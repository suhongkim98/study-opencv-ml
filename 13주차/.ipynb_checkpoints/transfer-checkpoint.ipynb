{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Flatten, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from  keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy  import expand_dims\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 개고양이 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "image_size = 224\n",
    "\n",
    "# 학습 이미지에 적용한 augmentation 인자를 지정해줍니다.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/smallcatdog/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # 모든 이미지의 크기가 150x150로 조정됩니다.\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/smallcatdog/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1)전이학습 : Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fcc70b41550> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70b41760> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70b41610> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcccbfcb850> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70b420d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70b42df0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc70b42dc0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70b56430> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70add1f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70adda90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc70addfa0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70ae5340> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70ae5220> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70aeb130> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc70ae5760> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70af49d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70af4640> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70aee7c0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc70af4fd0> False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 40,406,849\n",
      "Trainable params: 25,692,161\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "vgg_conv.summary()\n",
    "\n",
    "for layer in vgg_conv.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(vgg_conv)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 151s 1s/step - loss: 0.9035 - accuracy: 0.7995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc710e07f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)전이학습:Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fcc7088e940> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc7088eb50> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc708fb1f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc7088ea00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc7089b7c0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70825940> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc7088ef10> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc7081dbe0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc7089bd90> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70836880> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc7081dc40> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc708363d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70840970> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70844c70> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc7084bf40> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc7083ab80> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70854880> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fcc70850c40> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fcc7084bbb0> True\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 40,406,849\n",
      "Trainable params: 32,771,585\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    "\n",
    "# Add new layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 183s 1s/step - loss: 0.8741 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc7090fc40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 음식분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3347 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# 학습 이미지에 적용한 augmentation 인자를 지정해줍니다.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/food-11/training', \n",
    "        target_size=(224, 224), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/food-11/evaluation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f4be067b8e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4cd0792dc0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0c21190> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4cd0792220> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0c3b760> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0c75a90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4be0c48670> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0c957f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0c33d90> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0cad370> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4be0c335e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0beae20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0beabb0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0bee340> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4be0bead00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0bf2d90> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0bf0970> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4be0bf6e20> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4be0bf2d30> False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 15,251,275\n",
      "Trainable params: 536,587\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_conv.summary()\n",
    "\n",
    "for layer in vgg_conv.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(vgg_conv)\n",
    "\n",
    "model.add(GlobalAveragePooling2D())                       \n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssongkim/projects/study-opencv-ml/.venv/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-12-05 18:34:25.525769: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "617/617 [==============================] - 704s 1s/step - loss: 1.3962 - accuracy: 0.5245\n",
      "Epoch 2/10\n",
      "617/617 [==============================] - 701s 1s/step - loss: 1.0838 - accuracy: 0.6314\n",
      "Epoch 3/10\n",
      "617/617 [==============================] - 706s 1s/step - loss: 1.0035 - accuracy: 0.6546\n",
      "Epoch 4/10\n",
      "617/617 [==============================] - 704s 1s/step - loss: 0.9362 - accuracy: 0.6805\n",
      "Epoch 5/10\n",
      "617/617 [==============================] - 707s 1s/step - loss: 0.9081 - accuracy: 0.6893\n",
      "Epoch 6/10\n",
      "617/617 [==============================] - 700s 1s/step - loss: 0.8703 - accuracy: 0.6961\n",
      "Epoch 7/10\n",
      "617/617 [==============================] - 700s 1s/step - loss: 0.8430 - accuracy: 0.7119\n",
      "Epoch 8/10\n",
      "617/617 [==============================] - 701s 1s/step - loss: 0.8098 - accuracy: 0.7203\n",
      "Epoch 9/10\n",
      "617/617 [==============================] - 707s 1s/step - loss: 0.7771 - accuracy: 0.7341\n",
      "Epoch 10/10\n",
      "617/617 [==============================] - 703s 1s/step - loss: 0.7597 - accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssongkim/projects/study-opencv-ml/.venv/lib/python3.8/site-packages/keras/engine/training.py:2006: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
